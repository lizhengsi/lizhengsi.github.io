<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>基于hexo和github(coding)搭建博客</title>
    <url>/2018/02/27/%E5%9F%BA%E4%BA%8Ehexo%E5%92%8Cgithub-coding-%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>问术</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>github</tag>
        <tag>coding</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2016/08/30/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/deployment.html">Deployment</a></p>
]]></content>
      <categories>
        <category>问术</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Blog</tag>
      </tags>
  </entry>
  <entry>
    <title>关于Kalman滤波的理解</title>
    <url>/2020/08/30/%E5%85%B3%E4%BA%8E%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%9A%84%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<p>写在本文之前，有两个重要的思想需贯穿脑海之中：  </p>
<blockquote>
<p> 1. 没有绝对准确，只有更为接近的准确<br> 2. 滤波即为加权  关于1，这个不做多说。  </p>
</blockquote>
<p>关于2，对信号的滤波即是对离散序列的加权，传统的低通滤波器可以理解为高频权值为0（或接近0），而低频的权值为1，此时便可实现通低频阻高频的效果。同理，高通、带通滤波器可以理解为对不同频段的信号进行加权后获得想要的信号。 </p>
<a id="more"></a>

<hr>
<h1 id="1-基本概念"><a href="#1-基本概念" class="headerlink" title="1 基本概念"></a>1 基本概念</h1><h2 id="1-1-一些概念"><a href="#1-1-一些概念" class="headerlink" title="1.1 一些概念"></a>1.1 一些概念</h2><p>设X、Y为随机变量，$\mu$、$\nu$分别为X、Y的期望。x、y分别为X、Y的真实值，$\hat{x}$、$\hat{y}$分别为x、y的估计值，则有：</p>
<p><strong>误差</strong>：真实值与估计值的差，即$e=x-\hat{x}$</p>
<p><strong>方差</strong>：方差是描述随机变量与其期望值的离散程度，即$\sigma_{X}^{2}=E(X-E(X))$</p>
<p><strong>协方差</strong>：描述两个变量间的相关性，$cov(X,Y)=E[(X-\mu)(Y-\nu)]$ 。其中，X与Y的不相关是独立的必要不充分条件，但是对于X、Y正态分布时二者独立是不相关的充要条件。</p>
<p><strong>协方差矩阵</strong>：若$\mathrm{X}$为m维向量$\mathrm{X}=(X_{1},X_{2},…,X_{m})$，其中$X_{k}$中含一组数据；$\mathrm{Y}$为n维向量$\mathrm{Y}=(Y_{1},Y_{2},…,Y_{n})$，其中$Y_{k}$中含一组数据,则$\mathrm{X}$与$\mathrm{Y}$的协方差应表示为mxn维协方差矩阵：</p>
<p>$$<br>cov(\mathrm{X},\mathrm{Y})=E((\mathrm{X}-\mathrm{\mu})(\mathrm{Y}-\mathrm{\nu})^{T})=<br>\begin{bmatrix}<br>E[(X_{1}-\mu_{1})(Y_{1}-\nu_{1})] &amp; E[(X_{1}-\mu_{1})(Y_{2}-\nu_{2})] &amp;\cdots &amp;E[(X_{1}-\mu_{1})(Y_{n}-\nu_{n})] \ <br>E[(X_{2}-\mu_{2})(Y_{1}-\nu_{1})]&amp; E[(X_{2}-\mu_{2})(Y_{2}-\nu_{2})] &amp; \cdots  &amp;E[(X_{2}-\mu_{2})(Y_{n}-\nu_{n})] \ <br>\vdots                                         &amp; \vdots    &amp; \ddots    &amp; \vdots\<br>E[(X_{m}-\mu_{m})(Y_{1}-\nu_{1})]&amp;  E[(X_{m}-\mu_{m})(Y_{2}-\nu_{2})]&amp; \cdots  &amp; E[(X_{m}-\mu_{m})(Y_{n}-\nu_{n})]<br>\end{bmatrix}<br>$$<br>对于$\mathrm{X}$自身而言，其协方差矩阵(或称为方差，详见<a href="https://zh.wikipedia.org/wiki/%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5" title="wiki-协方差矩阵">wiki-协方差矩阵</a>)：<br>$$<br>cov(\mathrm{X},\mathrm{X})=E((\mathrm{X}-\mathrm{\mu})(\mathrm{X}-\mathrm{\mu})^{T})=<br>\begin{bmatrix}<br>E[(X_{1}-\mu_{1})(X_{1}-\mu_{1})] &amp; E[(X_{1}-\mu_{1})(X_{2}-\mu_{2})] &amp;\cdots &amp;E[(X_{1}-\mu_{1})(X_{n}-\mu_{n})] \ <br>E[(X_{2}-\mu_{2})(X_{1}-\mu_{1})]&amp; E[(X_{2}-\mu_{2})(X_{2}-\mu_{2})] &amp; \cdots  &amp;E[(X_{2}-\mu_{2})(X_{n}-\mu_{n})] \ <br>\vdots                                         &amp; \vdots    &amp; \ddots    &amp; \vdots\<br>E[(X_{m}-\mu_{m})(X_{1}-\mu_{1})]&amp;  E[(X_{m}-\mu_{m})(X_{2}-\mu_{2})]&amp; \cdots  &amp; E[(X_{m}-\mu_{m})(X_{n}-\mu_{n})]<br>\end{bmatrix}<br>$$<br>可以从上式可以看出，矩阵对角为$\mathrm{X}$列向量的方差。若$\mathrm{X}$服从正态分布，其为对角矩阵。（后面可将$\mathrm{X}$联想为状态向量，$X_{1}$、$X_{2}$联想为位移向量和速度向量）</p>
<p><strong>误差的协方差矩阵</strong>：若$\mathrm{X}$为m维向量$\mathrm{X}=(X_{1},X_{2},…,X_{m})$，其中$X_{k}$中含一组数据，误差为m维向量$\mathrm{e}$，则其误差的协方差矩阵为：<br>$$<br>P=cov(\mathrm{e},\mathrm{e})=E[\mathrm{e} \mathrm{e}^{T}]<br>$$<br><em>可知，其对角元素元素之和（或称迹）即为均方差。</em></p>
<blockquote>
<p> 注：此处十分重要，将状态变量的误差协方差矩阵与状态变量的最小均方差估计联系起来。</p>
</blockquote>
<h2 id="1-2-最小均方误差估计"><a href="#1-2-最小均方误差估计" class="headerlink" title="1.2 最小均方误差估计"></a>1.2 最小均方误差估计</h2><p><strong>均方误差</strong>：它是”误差”的平方的，也就是多个样本的时候，均方差等于每个样本的误差平方再乘以该样本出现的概率的和，即<br>$$<br>MSE=E[(x-\hat{x})^{2}]=E[e^{2}]<br>$$<br>若$\mathrm{X}$为m维向量$\mathrm{X}=(X_{1},X_{2},…,X_{m})$，其中$X_{k}$中含一组数据，则$\mathrm{X}$的均方误差：<br>$$<br>MSE=E[(\mathrm{x}-\mathrm{\hat{x}})^{T}(\mathrm{x}-\mathrm{\hat{x})}]=E[\mathrm{e}^{T}\mathrm{e}]=tr(E[\mathrm{e}\mathrm{e}^{T}])=\sum_{i=1}^{m}E[\mathrm{e}_{i}^{2}]<br>$$<br>注意，这里的$\mathrm{e}$为m维向量，$\mathrm{X}$的均方误差即为误差平方和的期望值，或误差平方的期望之和，这即是误差协方差矩阵的迹。</p>
<p><strong>最小均方差（MMSE）</strong>：对于变量$\mathrm{X}$，其最小均方误差即为：<br>$$<br>MMSE=MSE_{min}=E[(\mathrm{x}-\mathrm{\hat{x}})^{T}(\mathrm{x}-\mathrm{\hat{x})}]=E[\mathrm{e}^{T}\mathrm{e}]=tr(E[\mathrm{e}\mathrm{e}^{T}])=\sum_{i=1}^{m}E[\mathrm{e}<em>{i}^{2}]<br>$$<br><strong>最小均方误差估计</strong>：最小均方误差估计即最优估计，即寻找合适的估计函数$\hat{x}=c(x)$来估计x，使上式最小。<br>（1） X为一维变量时，该估计函数为：<br>$$<br>\hat{x}=E[X]<br>$$<br>其证明详见参考文献，大致过程是通过$MSE</em>{min}$对$\hat{x}$求导，令导函数为0，即可求得$\hat{x}$ 。  <br>（2） 当X存在先验条件Y时，该估计函数为：<br>$$<br>\hat{x}=E[X|Y=y]<br>$$<br>此时，该估计函数即为X在Y条件下的条件期望。其证明详见参考文献，证明过程同上。<br>（3） 当X存在先验条件Y，且X、Y为m为向量时，该估计函数为：<br>$$<br>\hat{x}(x_{1},x_{1},···,x_{m})=E[X|Y_{1}=y_{1},Y_{2}=y_{2},···,Y_{m}=y_{m}]<br>$$</p>
<h2 id="1-3-状态空间"><a href="#1-3-状态空间" class="headerlink" title="1.3 状态空间  "></a>1.3 状态空间  </h2><p>根据牛顿运动规律，物体的运动方程大体归结为化成如下形式：<br>$$<br>m\frac{\mathrm{d}^{2} x}{\mathrm{d} t^{2}}+2\beta \frac{\mathrm{d} x}{\mathrm{d} t}+kx=f(t)<br>$$<br>  化成以下形式：<br>$$<br>\ddot{x}-a_{1}\dot{x}-a_{0}x=f(t)<br>$$<br>再写成方程组形式：<br>$$<br> \left{\begin{matrix}\dot{x}=0\cdot x+1\cdot\dot{x}+0\cdot f(t) &amp; &amp; \ \ddot{x}=a_{0}x+a_{1}\dot{x}+1\cdot f(t)&amp; &amp; \end{matrix}\right.<br>$$<br>其矩阵形式：<br>$$<br> \begin{pmatrix}\dot{x}\ \ddot{x}\end{pmatrix}=  \begin{pmatrix}0 &amp; 1\ a_{0}&amp; a_{1}\end{pmatrix}\begin{pmatrix}\ x\ \dot{x}\end{pmatrix}  +  \begin{pmatrix}\ 0\ \ 1\end{pmatrix}f(t) <br>$$<br>化简为：<br>$$<br>\mathbf{\dot{x}}=\mathbf{Fx}+\mathbf{Gf}<br>$$<br> 如果在方程中加入过程噪声，则有：<br>$$<br>\ddot{x}=a_{1}\dot{x}+a_{0}x+f(t)+w(t)<br>$$<br> 得到类似矩阵：<br>$$<br>\begin{pmatrix}\dot{x}\ \ddot{x}\end{pmatrix}=  \begin{pmatrix}0 &amp; 1\ a_{0}&amp; a_{1}\end{pmatrix}\begin{pmatrix}\ x\ \dot{x}\end{pmatrix}  +\begin{pmatrix}\ 0\ \ 1\end{pmatrix}f(t)  +\begin{pmatrix}\ 0\ \ 1\end{pmatrix}w(t)<br>$$<br>简化为：<br>$$<br> \mathbf{\dot{x}}=\mathbf{Fx}+\mathbf{Gf}+\mathbf{w}<br>$$<br><em>其中，<strong>F</strong>：传输矩阵； <strong>x</strong>：状态矢量； <strong>G</strong>：控制矩阵； <strong>f</strong>：控制矢量； <strong>w</strong>：过程噪声</em>  </p>
<p><strong>在这里，状态向量$\mathbf=（x,\dot{x}）$包含位移和速度的信息。推广到多维空间，状态向量为$\mathbf=（x_{1},x_{2},…,x_{n};\dot{x_{1}},\dot{x_{2}},…,\dot{x_{n}}）$，这种方法称为状态空间描述法。</strong>  </p>
<hr>
<h1 id="2-Kalman滤波器"><a href="#2-Kalman滤波器" class="headerlink" title="2 Kalman滤波器"></a>2 Kalman滤波器</h1><h2 id="2-1-前提条件"><a href="#2-1-前提条件" class="headerlink" title="2.1 前提条件  "></a>2.1 前提条件  </h2><ul>
<li>线性系统  </li>
<li>系统噪声和测量噪声服从高斯分布  </li>
</ul>
<h2 id="2-2-系统模型"><a href="#2-2-系统模型" class="headerlink" title="2.2 系统模型"></a>2.2 系统模型</h2><p>卡尔曼滤波建立在线性代数和隐马尔可夫模型上，k时刻的状态在(k-1)时刻的基础上递推过来，系统模型由预测空间模型和观测空间模型组成。</p>
<p><strong>预测空间模型：</strong><br>$$<br>\mathbf{x_{k}}=\mathbf{Ax_{k-1}}+\mathbf{Bu_{k-1}}+\mathbf{w_{k-1}}<br>$$<br>其中：</p>
<ul>
<li>$\mathbf{x_{k}}$是k时刻的预测状态向量，$\mathbf{x_{k-1}}$是(k-1)时刻的状态向量  </li>
<li>$\mathbf{u_{k-1}}$是(k-1)时刻的控制输入向量</li>
<li>$\mathbf{A}$是k时刻状态传输矩阵，与系统本身特性相关，其隐含指示(k-1)时刻的状态会影响到k时刻的状态  </li>
<li>$\mathbf{B}$是k时刻控制输入矩阵，其隐含指示(k-1)时刻的驱动输入会影响到k时刻的状态  </li>
<li>$\mathbf{w_{k}}$是过程噪声，服从正态分布，$\mathbf{w_{k}}\sim N(0,Q_{k})$，$\mathbf{Q_{k}}$为其协方差矩阵  </li>
</ul>
<p><strong>观测空间模型：</strong><br>$$<br> \mathbf{z_{k}}=\mathbf{Hx_{k}}+\mathbf{v_{k}} <br>$$<br>  其中：</p>
<ul>
<li>$\mathbf{z_{k}}$是k时刻的观测状态向量  </li>
<li>$\mathbf{H}$是k时刻的观测矩阵，把真实状态空间映射成观测空间  </li>
<li>$\mathbf{v_{k}}$是观测噪声，服从正态分布，$\mathbf{v_{k}}\sim N(0,R_{k})$，$\mathbf{R_{k}}$为其协方差矩阵  </li>
</ul>
<p>分析上述两个状态方程，不拿看出，在k时刻的预测状态向量$\mathbf{x_{k}}$（或观测状态向量$\mathbf{z_{k}}$）是在第(k-1)时刻的状态上推导而来（马尔科夫模型），并且都在状态更新的过程中带入新的高斯噪声。</p>
<p>那么问题来了，既然既可以通过预测，亦可以通过观测，来获知系统在k时刻的状态，但是二者都存在误差（噪声），那么二者哪个更可靠呢？这时，我们自然而然的想到了的加权的思想，通过对二者的加权获得k时刻的准确的状态。  通过以下图片可以帮我们更好地理解，小车距出发地的距离可以通过预测模型和测量模型获得，且二者都服从正态分布，都存在误差。通过对二者加权，得到我们想要的较为准确的状态模型（图中绿色表示），但是，这个模型也存在误差，服从正态分布。 </p>
<p><img src="C:/Users/Jian/OneDrive/%E5%9B%BE%E5%BA%8A/%E7%A4%BA%E4%BE%8B%E5%B0%8F%E8%BD%A601.jpg" alt="示例小车01" title="示例小车01"></p>
<p><img src="C:/Users/Jian/OneDrive/%E5%9B%BE%E5%BA%8A/%E7%A4%BA%E4%BE%8B%E5%B0%8F%E8%BD%A602.jpg" alt="示例小车01" title="示例小车02"></p>
<p><img src="C:/Users/Jian/OneDrive/%E5%9B%BE%E5%BA%8A/%E7%A4%BA%E4%BE%8B%E5%B0%8F%E8%BD%A603.jpg" alt="示例小车01" title="示例小车03"></p>
<p><img src="C:/Users/Jian/OneDrive/%E5%9B%BE%E5%BA%8A/%E7%A4%BA%E4%BE%8B%E5%B0%8F%E8%BD%A604.jpg" alt="示例小车04"></p>
<p><strong>综上，kalman滤波即是对预测模型和观测模型进行加权处理，获取更加接近实际值新的状态估计值。实际上，kalman滤波即是利用观测模型的残差来修正预测模型（最优估计），同时计算残差的权值。</strong>  </p>
<h2 id="2-3-递推方程"><a href="#2-3-递推方程" class="headerlink" title="2.3 递推方程"></a>2.3 递推方程</h2><p>kalman滤波器用于估计离散时间过程的状态变量$x\in\Re^{n}$，这个离散时间过程由以下离散随机差分方程描述：</p>
<p>设$\mathbf{x}<em>{k}^{-}\in\Re^{n}$(-代表先验，^代表估计)为在已知第 k步以前状态情况下第 k 步的先验状态估计。$\mathbf{\hat{x}}</em>{k}\in\Re^{n}$为已知测量变量$\mathbf{z}<em>{k}$时第k步的后验状态估计。由此定义先验估计误差和后验估计误差：<br>$$<br>\mathbf{e</em>{k}^{-}}=\mathbf{x_{k}} - \mathbf{\hat{x}<em>{k}^{-}}  ,  \mathbf{e</em>{k}}=\mathbf{x_{k}}  -  \mathbf{\hat{x}<em>{k}}<br>$$<br>先验估计误差的协方差为：<br>$$<br>\mathbf{P</em>{k}^{-}} = E[\mathbf{e_{k}^{-}}  \mathbf{(e_{k}^{-})^{T}}]<br>$$<br>后验估计误差的协方差为：<br>$$<br>\mathbf{P_{k}} = E[\mathbf{e_{k}}  \mathbf{(e_{k})^{T}}]<br>$$<br>那么，对于预测和测量状态空间方程，即为：</p>
<p><strong>预测空间模型-预测值（先验估计）：</strong><br>$$<br> \mathbf{\hat{x}<em>{k}^{-}}=\mathbf{A\hat{x}</em>{k-1}}+\mathbf{B\hat{u}<em>{k-1}}<br>$$<br><strong>观测空间模型-测量值（测量值的预测）：</strong><br>$$<br>\mathbf{\hat{z}</em>{k}}=\mathbf{H\hat{x}_{k}^{-}}<br>$$</p>
<blockquote>
<p> 实际测量值为：$ \mathbf{z_{k}}=\mathbf{H\hat{x}<em>{k}^{-}} + \mathbf{v</em>{k}} = \mathbf{\hat{z}<em>{k}} + \mathbf{v</em>{k}}$</p>
</blockquote>
<p><strong>Kalman滤波器：</strong><br>这时，要在测量值的基础上再次更新先验估计，可得到后验估计，得到最优估计$\mathbf{\hat{x}<em>{k}}$：<br>$$<br>\mathbf{\hat{x}</em>{k}} = \mathbf{\hat{x}<em>{k}^{-}} + \mathbf{K</em>{k}} (\mathbf{z_{k}} - \mathbf{H} \mathbf{\hat{x}<em>{k}^{-}})<br>$$<br>上式构造了kalman滤波器的表达式，先验估计$\mathbf{\hat{x}</em>{k}^{-}}$和加权的预测残差$(\mathbf{z_{k}} - \mathbf{H} \mathbf{\hat{x}<em>{k}^{-}})$线性的构成了后验状态估计$\mathbf{\hat{x}</em>{k}}$。</p>
<blockquote>
<p> (1)  $\mathbf{x_{k}}$ 的概率原型。这个可以见参考文献，来源于贝叶斯规则：$\mathbf{\hat{x}<em>{k}}$的更新取决于在已知先前的测量变量$\mathbf{z</em>{k}}$的情况下$\mathbf{\hat{x}<em>{k}}$的先验估计$\mathbf{\hat{x}</em>{k}^{-}}$的概率分布。在已知 $\mathbf{z_{k}}$的情况下，$\mathbf{\hat{x}<em>{k}}$的分布可写为：<br>$$<br>p(\mathbf{x</em>{k}} | \mathbf{z_{k}}) - N(\mathbf{\hat{x}<em>{k}},\mathbf{P</em>{k}})<br>$$<br>即为正态分布。</p>
</blockquote>
<blockquote>
<p> (2)  $\mathbf{\hat{x}<em>{k}}$的推导。关于$\mathbf{\hat{x}</em>{k}}$的形式，这里应该是利用了反馈的原理（如下面这张图），或是最优估计的原理，在知乎上看到有说用极大似然估计可以推导，但是，具体推导还不是很清楚。在论文中还看到过一种是将预测和测量的正态分布相乘求联合正态分布，联合正态分布即为后验状态估计。</p>
<p><img src="C:/Users/Jian/OneDrive/%E5%9B%BE%E5%BA%8A/ea724e869ec237ab4dc8bac75abef832_b.png" alt="kalman filter controller"></p>
</blockquote>
<blockquote>
<p> (3)  $\mathbf{K_{k}}$值的推导。既然$\mathbf{\hat{x}<em>{k}}$是$\mathbf{x</em>{k}}$的最优估计，那么$\mathbf{x_{k}}$的误差协方差矩阵的迹$tr[\mathbf{P_{k}}]$($\mathbf{P_{k}}$的计算见下面)最小即$\mathbf{x_{k}}$的均方误差最小。此时，将后验估计$\mathbf{\hat{x}<em>{k}}$的表达式和误差协方差矩阵$\mathbf{P</em>{k}}$的表达式联立，即可求得$tr[\mathbf{P_{k}}]$，对其求导，导函数为零时求得$\mathbf{K_{k}}$：<br>$$<br>\mathbf{K_{k}} = \mathbf{P_{k}^{-}}\mathbf{H^{T}}(\mathbf{H}\mathbf{P_{k}^{-}}\mathbf{H^{T}}+\mathbf{R})^{-1}= <br>\frac{\mathbf{P_{k}^{-}}\mathbf{H^{T}}}{\mathbf{H}\mathbf{P_{k}^{-}}\mathbf{H^{T}}+\mathbf{R}}<br>$$</p>
</blockquote>
<p>还有另外一种表达形式，这里是对k时刻的测量值和（k-1）时刻状态估计值进行加权<br><img src="E:/Nutstore/%E5%9B%BE%E5%BA%8A/index_files/e9c67db4-cdb7-4149-9ac5-9fc9d1f97c66.jpg"></p>
<h2 id="2-4-离散Kalman滤波器算法"><a href="#2-4-离散Kalman滤波器算法" class="headerlink" title="2.4 离散Kalman滤波器算法"></a>2.4 离散Kalman滤波器算法</h2><p>卡尔曼滤波器用反馈控制的方法估计过程状态：滤波器估计某一时刻的过程状态，然后以测量变量（含噪声）的方式获得反馈。</p>
<p>因此卡尔曼滤波器可分为两个部分：时间更新方程和测量更新方程。时间更新方程负责及时向前推算当前状态变量和误差协方差估计的值，以便为下一个时间状态构造先验估计。测量更新方程负责反馈，它将先验估计和新的测量变量结合以构造改进的后验估计。时间更新方程也可视为预估方程，测量更新方程可视为校正方程。最后的估计算法成为一种具有数值解的预估－校正算法。<br><img src="E:/Nutstore/%E5%9B%BE%E5%BA%8A/index_files/0ae38f36-2a09-4fec-a484-fb10c2e64609.png"></p>
<p><strong>离散卡尔曼滤波时间更新方程</strong><br>$$<br>\left{\begin{matrix}<br>\mathbf{\hat{x}<em>{k}^{-}}=\mathbf{A\hat{x}</em>{k-1}}+\mathbf{Bu_{k-1}}<br>\ <br>\mathbf{P_{k}^{-}}=\mathbf{A} \boldsymbol{P_{k-1}} \mathbf{A^{T}} + \mathbf{Q}<br>\end{matrix}\right.<br>$$<br>时间更新方程主要获取由预测方程预测的k时刻的状态$\mathbf{\hat{x}<em>{k}^{-}}$，为$\mathbf{\hat{x}</em>{k}}$的先验状态估计；此时，其误差的协方差矩阵为$\mathbf{P_{k}^{-}}$。</p>
<blockquote>
<p> 上式中，存在未知参数$\mathbf{A}$, $\mathbf{B}$, $\mathbf{P_{k}^{-}}$, $\mathbf{P_{k-1}}$, $\mathbf{Q}$<br>(1) 关于$\mathbf{A}$。这是和状态向量相关的矩阵，具体见举例<br>(2) 关于$\mathbf{B}$。这是驱动矩阵，和外部输入驱动有关，具体见举例<br>(3) 关于 $\mathbf{P_{k}^{-}}$。这是k时刻的先验状态估计的误差协方差矩阵，与预测方程的噪声有关，是根据（k-1）时刻的误差协方差矩阵$\mathbf{P_{k-1}}$递推而来（$\mathbf{P_{k-1}}$一般是给定的初值），利用$\mathbf{P_{k}^{-}}$的表达式 $\mathbf{P_{k}^{-}} = E[\mathbf{e_{k}^{-}}  \mathbf{(e_{k}^{-})^{T}}]$即可求得。<br>(4) 关于$\mathbf{P_{k-1}}$。（k-1）时刻的误差协方差矩阵（$\mathbf{P_{k-1}}$一般是给定的初值）<br>(5) 关于$\mathbf{Q}$。过程噪声（预测误差）$\mathbf{w_{k-1}}$的协方差矩阵，在预测的过程中产生。</p>
</blockquote>
<p><strong>离散卡尔曼滤波状态更新方程</strong><br>$$<br>\left{\begin{matrix}<br>\mathbf{K_{k}} = \mathbf{P_{k}^{-}}\mathbf{H^{T}}(\mathbf{H}\mathbf{P_{k}^{-}}\mathbf{H^{T}}+\mathbf{R})^{-1}<br>\<br>\mathbf{\hat{x}<em>{k}} = \mathbf{\hat{x}</em>{k}^{-}} + \mathbf{K_{k}} (\mathbf{z_{k}} - \mathbf{H} \mathbf{\hat{x}<em>{k}^{-}})<br>\ <br>\mathbf{P</em>{k}}=(\mathbf{I} - \mathbf{K_{k}}\mathbf{H} )\mathbf{P_{k}^{-}}<br>\end{matrix}\right.<br>$$<br>状态更新方程在预测的先验估计$\mathbf{\hat{x}<em>{k}^{-}}$上，同测量值$\mathbf{z</em>{k}}$进行融合，更新校正先验状态估计，得到k时刻的后验状态估计$\mathbf{\hat{x}<em>{k}}$；此时，递推出后验状态估计的误差协方差矩阵$\mathbf{P</em>{k}}$，由此可以得到MMSE的条件，求得$\mathbf{K_{k}}$</p>
<blockquote>
<p> 上式中，存在未知参数$\mathbf{K_{k}}$, $\mathbf{H}$, $\mathbf{R}$, $\mathbf{z_{k}}$, $\mathbf{P_{k}}$<br>(1) 关于$\mathbf{K_{k}}$。残差（真实测量值与基于先验状态估计的测量值（估计量））的增益，可以看做测量反馈的增益<br>(2) 关于$\mathbf{H}$。这是观测矩阵，和状态向量有关，具体见举例<br>(3) 关于$\mathbf{R}$。测量噪声（测量误差）$\mathbf{v_{k-1}}$的协方差矩阵，在测量的过程中产生。 <br>(4) 关于$\mathbf{z_{k}}$。k时刻的真是测量值。<br>(5) 关于$\mathbf{P_{k}}$。k时刻的后验估计的误差协方差矩阵。</p>
</blockquote>
<p>因此，通过时间更新和测量更新的不断递推，便可得到比较准确的状态向量估计值。其中，若初始过程噪声$w_{k}$和测量噪声$v_{k}$为一确定值，不断递推后状态向量误差协方差矩阵$\mathbf{P_{k}}$和卡尔曼增益$\mathbf{K_{k}}$会收敛并保持常量。<br><img src="E:/Nutstore/%E5%9B%BE%E5%BA%8A/index_files/c6c9194a-0821-4124-b1ec-7005dff8174a.png"></p>
<hr>
<h1 id="3-程序"><a href="#3-程序" class="headerlink" title="3 程序  "></a>3 程序  </h1><h2 id="3-1-Matlab程序"><a href="#3-1-Matlab程序" class="headerlink" title="3.1 Matlab程序  "></a>3.1 Matlab程序  </h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">% kalman filter</span><br><span class="line"></span><br><span class="line">% x(k+1) &#x3D; Fk * x(k) + Wk; 预测模型</span><br><span class="line">% y(k)   &#x3D; Hk * x(k) + Vk; 观测模型</span><br><span class="line"></span><br><span class="line">N &#x3D; 365;</span><br><span class="line"></span><br><span class="line">Fk &#x3D; [1];               % 状态转移矩阵               </span><br><span class="line">X  &#x3D; zeros(N,1);        % 初始化状态变量</span><br><span class="line">W  &#x3D; 12*randn(N,1);     % 构造过程噪声</span><br><span class="line">X(1) &#x3D; 100;             % 初始状态</span><br><span class="line">                    </span><br><span class="line">for k &#x3D; 2:N</span><br><span class="line">    % 状态方程</span><br><span class="line">    X(k) &#x3D; Fk * X(k-1) + W(k-1);</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">Hk &#x3D; [2];               % 观测矩阵                </span><br><span class="line">Y  &#x3D; zeros(N,1);        % 初始化观测变量</span><br><span class="line">V  &#x3D; 20*randn(N,1);     % 构造观测噪声</span><br><span class="line"></span><br><span class="line">for k &#x3D; 1:N</span><br><span class="line">    % 观测方程</span><br><span class="line">    Y(k) &#x3D; Hk * X(k) + V(k);   </span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">Q  &#x3D; cov(W);            % 过程噪声协方差；    </span><br><span class="line">R  &#x3D; cov(V);            % 观测噪声协方差；          </span><br><span class="line"></span><br><span class="line">Xupdate &#x3D; zeros(N,1);   </span><br><span class="line">Xupdate(1) &#x3D; Y(1);      % 初始化第一个，也就是观测到的第一个 </span><br><span class="line">Pupdate(1) &#x3D; 0;</span><br><span class="line">for k &#x3D; 2:N</span><br><span class="line">    % 五大核心方程</span><br><span class="line">    Xpredict(k) &#x3D; Fk * Xupdate(k-1);</span><br><span class="line">    Ppredict(k) &#x3D; Fk * Pupdate(k-1) * Fk&#39; + Q;</span><br><span class="line">    K &#x3D; Ppredict(k) * Hk * (Hk * Ppredict(k) * Hk&#39; + R).^-1;</span><br><span class="line">    Xupdate(k) &#x3D; (1 - K * Hk) * Xpredict(k) + K * Y(k);</span><br><span class="line">    Pupdate(k) &#x3D; (1 - K * Hk) * Ppredict(k);</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">plot(1:N,X,&#39;B&#39;,&#39;linewidth&#39;,2);hold on;</span><br><span class="line">plot(1:N,Y,&#39;K&#39;,&#39;linewidth&#39;,2);hold on;</span><br><span class="line">plot(1:N,Xupdate,&#39;R&#39;,&#39;linewidth&#39;,2);hold on;</span><br><span class="line">plot(1:N,abs(Xupdate-X),&#39;m&#39;,&#39;linewidth&#39;,2);hold off;</span><br><span class="line">legend(&#39;真值&#39;,&#39;观测值&#39;,&#39;滤波值&#39;,&#39;误差&#39;)</span><br></pre></td></tr></table></figure>

<h2 id="3-2-C程序"><a href="#3-2-C程序" class="headerlink" title="3.2 C程序"></a>3.2 C程序</h2><hr>
<h1 id="4-参考"><a href="#4-参考" class="headerlink" title="4 参考"></a>4 参考</h1><ul>
<li><a href="https://www.zhihu.com/question/23971601">https://www.zhihu.com/question/23971601</a>  </li>
<li><a href="http://blog.csdn.net/xiahouzuoxin/article/details/39582483">http://blog.csdn.net/xiahouzuoxin/article/details/39582483</a>  </li>
<li><a href="https://zhuanlan.zhihu.com/p/21889676">https://zhuanlan.zhihu.com/p/21889676</a>  </li>
<li><a href="https://zh.wikipedia.org/wiki/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2">https://zh.wikipedia.org/wiki/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2</a>  </li>
<li><a href="https://zh.wikipedia.org/wiki/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95">https://zh.wikipedia.org/wiki/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95</a></li>
<li><a href="http://www.jianshu.com/p/2768642e3abf">http://www.jianshu.com/p/2768642e3abf</a></li>
<li><a href="http://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/">http://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/</a></li>
<li>Ramsey Faragher. Understanding the Basis of the Kalman Filter. 2012</li>
<li>Greg Welch, Gary Bishop. An Introduction to the Kalman Filter. 2001</li>
<li>Don Johnson. Minimum Mean Squared Error Estimators. 2004</li>
<li>R.E.Kalman. A new approach to linear filtering and prediction problems. 1960</li>
</ul>
]]></content>
      <categories>
        <category>问术</category>
      </categories>
      <tags>
        <tag>Kalman滤波</tag>
      </tags>
  </entry>
</search>
